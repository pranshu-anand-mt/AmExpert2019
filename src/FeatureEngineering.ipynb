{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip --quiet\n",
    "# !pip install -r requirements.txt --quiet\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import numpy as np  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score as roc_auc_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import datetime\n",
    "from dateutil.rrule import rrule, DAILY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "#     current_file = os.path.abspath(os.path.dirname())\n",
    "    current_file = \"\"\n",
    "\n",
    "    csv_filename = os.path.join(current_file, './cleaned_data/campaign_data.csv')\n",
    "    campaign_data = pd.read_csv(csv_filename)\n",
    "\n",
    "    csv_filename = os.path.join(current_file, './cleaned_data/coupon_item_mapping_data.csv')\n",
    "    coupon_item_mapping_data = pd.read_csv(csv_filename)\n",
    "\n",
    "    csv_filename = os.path.join(current_file, './cleaned_data/customer_demographics_data.csv')\n",
    "    customer_demographics_data = pd.read_csv(csv_filename)\n",
    "\n",
    "    csv_filename = os.path.join(current_file, './cleaned_data/customer_transaction_data.csv')\n",
    "    customer_transaction_data = pd.read_csv(csv_filename)\n",
    "\n",
    "    csv_filename = os.path.join(current_file, './cleaned_data/item_data.csv')\n",
    "    item_data = pd.read_csv(csv_filename)\n",
    "\n",
    "    csv_filename = os.path.join(current_file, './cleaned_data/train_data.csv')\n",
    "    train_data = pd.read_csv(csv_filename)\n",
    "\n",
    "    csv_filename = os.path.join(current_file, '../test_data/test_QyjYwdj.csv')\n",
    "    test_data = pd.read_csv(csv_filename)\n",
    "    \n",
    "    return campaign_data, coupon_item_mapping_data, customer_demographics_data, \\\n",
    "           customer_transaction_data, item_data, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_data, coupon_item_mapping_data, customer_demographics_data, \\\n",
    "customer_transaction_data, item_data, train_data, test_data = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: submissions: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir submissions\n",
    "\n",
    "def save_submission(predictions_probability):\n",
    "    predictions_probability = pd.DataFrame(predictions_probability)[1]\n",
    "    submission_df = pd.concat([test_data['id'], pd.Series(predictions_probability, name=\"redemption_status\")], axis=1)\n",
    "\n",
    "    submission_file_name = \"submissions/\" + str(int(time.time())) + \".csv\"\n",
    "\n",
    "    submission_df.to_csv(submission_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation_matrix(train_data, predictions, predictions_probability):\n",
    "    print(confusion_matrix(train_data['redemption_status'], predictions))\n",
    "    print(roc_auc_score(train_data['redemption_status'], pd.DataFrame(predictions_probability)[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression(solver='liblinear')\n",
    "classifier.fit(train_data.drop(columns=['id', 'redemption_status']), train_data['redemption_status'])\n",
    "\n",
    "predictions_test = classifier.predict(test_data.drop(columns=['id']))\n",
    "predictions_test_probability = classifier.predict_proba(test_data.drop(columns=['id']))\n",
    "\n",
    "predictions_train = classifier.predict(train_data.drop(columns=['id', 'redemption_status']))\n",
    "predictions_train_probability = classifier.predict_proba(train_data.drop(columns=['id', 'redemption_status']))\n",
    "\n",
    "save_submission(predictions_test_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[77640     0]\n",
      " [  729     0]]\n",
      "0.5746672942333827\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_matrix(train_data, predictions_train, predictions_train_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_one_hot_encoder(df, column_name):\n",
    "    one_hot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    category_df = pd.DataFrame(df[column_name])\n",
    "    encoded_categories = one_hot_encoder.fit_transform(category_df)\n",
    "    \n",
    "    encoded_df = pd.DataFrame(encoded_categories.toarray(), columns=one_hot_encoder.get_feature_names([column_name]))\n",
    "   \n",
    "    return pd.concat([df, encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## campaign_data feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_overlap_duration(start_date, end_date, intervals_df):\n",
    "    dates_to_check_against = set(\n",
    "        [dt for dt in rrule(DAILY, dtstart=start_date_in_question, until=end_date_in_question)])\n",
    "    \n",
    "    number_of_dates_originally = len(dates_to_check_against)\n",
    "    \n",
    "    for i in intervals_df.index:\n",
    "        dates_to_check = set(\n",
    "        [dt for dt in rrule(DAILY, dtstart=intervals_df.start_date[i], until=intervals_df.end_date[i])])\n",
    "    \n",
    "        dates_to_check_against = dates_to_check_against.difference(dates_to_check)\n",
    "        \n",
    "    \n",
    "    return number_of_dates_originally - len(dates_to_check_against)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_campaign_runs(campaign_data, custom_parameter=False):\n",
    "\n",
    "    campaign_data.start_date = pd.to_datetime(campaign_data.start_date)\n",
    "    campaign_data.end_date = pd.to_datetime(campaign_data.end_date)\n",
    "\n",
    "\n",
    "    same_type_overlapping_campaigns = []\n",
    "    other_type_overlapping_campaigns = []\n",
    "    same_type_overlap_duration = []\n",
    "    other_type_overlap_duration = []\n",
    "    duration_in_days = []\n",
    "    months = []\n",
    "    number_of_weekends = []\n",
    "\n",
    "    for i in campaign_data.index: \n",
    "        campaign_type_in_question = campaign_data.campaign_type[i]\n",
    "        start_date_in_question = campaign_data.start_date[i]\n",
    "        end_date_in_question = campaign_data.end_date[i]\n",
    "\n",
    "        cond_2 = (campaign_data.start_date <= start_date_in_question) & (campaign_data.end_date >= start_date_in_question) \n",
    "        cond_1 = (campaign_data.start_date >= start_date_in_question) & (campaign_data.start_date <= end_date_in_question) \n",
    "        cond_overlapping_campaigns = (cond_1) | (cond_2)\n",
    "\n",
    "        cond_same_type = (campaign_data.campaign_type == campaign_type_in_question) \n",
    "        cond_other_type = (campaign_data.campaign_type != campaign_type_in_question) \n",
    "\n",
    "        cond_same_type = (cond_overlapping_campaigns) & (cond_same_type)\n",
    "        cond_other_type = (cond_overlapping_campaigns) & (cond_other_type)\n",
    "\n",
    "        # Same-type metrics\n",
    "        same_type_campaigns = campaign_data.loc[cond_same_type]\n",
    "\n",
    "        same_type_overlapping_campaigns_count = same_type_campaigns.shape[0] - 1\n",
    "        same_type_overlapping_campaigns.append(same_type_overlapping_campaigns_count)\n",
    "\n",
    "        same_type_overlap_duration_for_this_campaign = find_overlap_duration(\\\n",
    "            start_date_in_question, end_date_in_question, same_type_campaigns[['start_date', 'end_date']])\n",
    "        same_type_overlap_duration.append(same_type_overlap_duration_for_this_campaign)\n",
    "\n",
    "\n",
    "        # Other-type metrics\n",
    "        other_type_campaigns = campaign_data.loc[cond_other_type]\n",
    "\n",
    "        other_type_overlapping_campaigns_count = other_type_campaigns.shape[0]\n",
    "        other_type_overlapping_campaigns.append(other_type_overlapping_campaigns_count)\n",
    "\n",
    "        other_type_overlap_duration_for_this_campaign = find_overlap_duration(\\\n",
    "            start_date_in_question, end_date_in_question, other_type_campaigns[['start_date', 'end_date']])\n",
    "        other_type_overlap_duration.append(other_type_overlap_duration_for_this_campaign)\n",
    "\n",
    "\n",
    "        # Months Running\n",
    "        dates_running = set(rrule(DAILY, dtstart=start_date_in_question, until=end_date_in_question))\n",
    "        months_for_this_challenge = list(set([dt.month for dt in dates_running]))\n",
    "        months.append(months_for_this_challenge)\n",
    "\n",
    "        # Duration\n",
    "        duration_in_days_for_this_challenge = len(dates_running)\n",
    "        duration_in_days.append(duration_in_days_for_this_challenge)\n",
    "        \n",
    "        # Weekends\n",
    "        number_of_weekends_for_this_challenge = sum([dt.isoweekday() >= 6 for dt in list(dates_running)])\n",
    "        number_of_weekends.append(number_of_weekends_for_this_challenge)\n",
    "        \n",
    "    campaign_data['duration_in_days'] = pd.Series(duration_in_days, name='duration_in_days')\n",
    "    campaign_data['months'] = pd.Series(months, name='months')\n",
    "    campaign_data['same_type_overlapping_campaigns'] = pd.Series(same_type_overlapping_campaigns, name='same_type_overlapping_campaigns')\n",
    "    campaign_data['other_type_overlapping_campaigns'] = pd.Series(other_type_overlapping_campaigns, name='other_type_overlapping_campaigns_count')\n",
    "    campaign_data['same_type_overlap_duration'] = pd.Series(same_type_overlap_duration, name='same_type_overlap_duration')\n",
    "    campaign_data['other_type_overlap_duration'] = pd.Series(other_type_overlap_duration, name='other_type_overlap_duration')\n",
    "    campaign_data['number_of_weekends'] = pd.Series(number_of_weekends, name='number_of_weekends')\n",
    "\n",
    "#     return np.c_[campaign_data]\n",
    "    return campaign_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_feature_binarizer(df):\n",
    "    months_array = df['months']\n",
    "    multi_label_binarizer = MultiLabelBinarizer()\n",
    "    months_encoded = multi_label_binarizer.fit_transform(months_array)\n",
    "\n",
    "    months_encoded_df = pd.DataFrame(months_encoded, columns=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "    return pd.concat([df, months_encoded_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline - for campaign_data table feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_to_process = list(campaign_data.columns.values)\n",
    "\n",
    "campaign_type_processor = Pipeline([\n",
    "    ('selector', DataFrameSelector(attributes_to_process)),\n",
    "    ('analyzer', FunctionTransformer(analyse_campaign_runs, validate=False, \n",
    "                                             kw_args={\"custom_parameter\": False})),\n",
    "    ('month_labelizer', FunctionTransformer(month_feature_binarizer, validate=False)),\n",
    "    ('one_hot_encoder', FunctionTransformer(custom_one_hot_encoder, validate=False, \n",
    "                                            kw_args={\"column_name\": 'campaign_type'}))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_data = campaign_type_processor.fit_transform(campaign_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_data.to_csv(path_or_buf=\"./campaign_data_with_original_and_new_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'campaign_type', 'start_date', 'end_date',\n",
       "       'duration_in_days', 'months', 'same_type_overlapping_campaigns',\n",
       "       'other_type_overlapping_campaigns', 'same_type_overlap_duration',\n",
       "       'other_type_overlap_duration', 'number_of_weekends', 'Jan', 'Feb',\n",
       "       'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec',\n",
       "       'campaign_type_X', 'campaign_type_Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "campaign_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['campaign_id', 'duration_in_days', 'same_type_overlapping_campaigns',\n",
       "       'other_type_overlapping_campaigns', 'same_type_overlap_duration',\n",
       "       'other_type_overlap_duration', 'number_of_weekends', 'Jan', 'Feb',\n",
       "       'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec',\n",
       "       'campaign_type_X', 'campaign_type_Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "campaign_data_new_features = campaign_data.drop(columns=['start_date', 'end_date', 'campaign_type', 'months'])\n",
    "campaign_data_new_features.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                     'campaign_id',                    'campaign_type',\n",
       "                             'start_date',                         'end_date',\n",
       "                       'duration_in_days',                           'months',\n",
       "        'same_type_overlapping_campaigns', 'other_type_overlapping_campaigns',\n",
       "             'same_type_overlap_duration',      'other_type_overlap_duration',\n",
       "                     'number_of_weekends',                              'Jan',\n",
       "                                    'Feb',                              'Mar',\n",
       "                                    'Apr',                              'May',\n",
       "                                    'Jun',                              'Jul',\n",
       "                                    'Aug',                              'Sep',\n",
       "                                    'Oct',                              'Nov',\n",
       "                                    'Dec',                             ('X',),\n",
       "                                   ('Y',)],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "campaign_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_data_filtered = campaign_data.drop(columns=['months', 'start_date', 'end_date', 'campaign_type'])\n",
    "campaign_data_filtered = campaign_data_filtered.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sample(df, column_name, multiplier=2):\n",
    "    for i in range(multiplier):\n",
    "        df = pd.concat([df, df.loc[df[column_name] == 1]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model - 2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_data_to_be_used = train_data.merge(campaign_data_filtered, on=['campaign_id'], how='left') \\\n",
    ".drop(columns=['campaign_id', 'customer_id', 'coupon_id'])\n",
    "test_data_to_be_used = test_data.merge(campaign_data_filtered, on=['campaign_id'], how='left') \\\n",
    ".drop(columns=['campaign_id', 'customer_id', 'coupon_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(solver='liblinear')\n",
    "classifier.fit(train_data_to_be_used.drop(columns=['id', 'redemption_status']), train_data['redemption_status'])\n",
    "\n",
    "predictions_test = classifier.predict(test_data_to_be_used.drop(columns=['id']))\n",
    "predictions_test_probability = classifier.predict_proba(test_data_to_be_used.drop(columns=['id']))\n",
    "\n",
    "predictions_train = classifier.predict(train_data_to_be_used.drop(columns=['id', 'redemption_status']))\n",
    "predictions_train_probability = classifier.predict_proba(train_data_to_be_used.drop(columns=['id', 'redemption_status']))\n",
    "\n",
    "save_submission(predictions_test_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Nov</td>\n",
       "      <td>-0.938946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>(Y,)</td>\n",
       "      <td>-0.900358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Mar</td>\n",
       "      <td>-0.613077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>May</td>\n",
       "      <td>-0.606725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Aug</td>\n",
       "      <td>-0.432949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>same_type_overlapping_campaigns</td>\n",
       "      <td>-0.427315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>(X,)</td>\n",
       "      <td>-0.313662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>other_type_overlapping_campaigns</td>\n",
       "      <td>-0.258188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Sep</td>\n",
       "      <td>-0.204838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Apr</td>\n",
       "      <td>-0.135344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Jun</td>\n",
       "      <td>-0.110644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>duration_in_days</td>\n",
       "      <td>-0.041087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>other_type_overlap_duration</td>\n",
       "      <td>-0.008913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>same_type_overlap_duration</td>\n",
       "      <td>-0.002944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Dec</td>\n",
       "      <td>0.124185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Jan</td>\n",
       "      <td>0.244545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Jul</td>\n",
       "      <td>0.567637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Feb</td>\n",
       "      <td>0.593816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Oct</td>\n",
       "      <td>0.944858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              column      coef\n",
       "15                               Nov -0.938946\n",
       "18                              (Y,) -0.900358\n",
       "7                                Mar -0.613077\n",
       "9                                May -0.606725\n",
       "12                               Aug -0.432949\n",
       "1    same_type_overlapping_campaigns -0.427315\n",
       "17                              (X,) -0.313662\n",
       "2   other_type_overlapping_campaigns -0.258188\n",
       "13                               Sep -0.204838\n",
       "8                                Apr -0.135344\n",
       "10                               Jun -0.110644\n",
       "0                   duration_in_days -0.041087\n",
       "4        other_type_overlap_duration -0.008913\n",
       "3         same_type_overlap_duration -0.002944\n",
       "16                               Dec  0.124185\n",
       "5                                Jan  0.244545\n",
       "11                               Jul  0.567637\n",
       "6                                Feb  0.593816\n",
       "14                               Oct  0.944858"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef = pd.Series(classifier.coef_[0])\n",
    "columns = pd.Series(train_data_to_be_used.drop(columns=['id', 'redemption_status']).columns)\n",
    "feature_importance = pd.DataFrame()\n",
    "feature_importance['column'] = columns\n",
    "feature_importance['coef'] = coef\n",
    "feature_importance.sort_values(['coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[77640     0]\n",
      " [  729     0]]\n",
      "0.6267155522057062\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_matrix(train_data, predictions_train, predictions_train_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abc = pd.concat([xyz, xyz.loc[xyz.redemption_status == 1], xyz.loc[xyz.redemption_status == 1], xyz.loc[xyz.redemption_status == 1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
